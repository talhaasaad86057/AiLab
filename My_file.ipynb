{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74QMaaMfAVPW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1. IMPORT LIBRARIES\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# ==============================\n",
        "# 2. PARAMETERS (HIGH LEVEL)\n",
        "# ==============================\n",
        "max_features = 15000    # Vocabulary size\n",
        "maxlen = 200            # Sequence length\n",
        "embedding_dim = 64      # Embedding dimension\n",
        "lstm_units = 64         # LSTM units\n",
        "cnn_filters = 64        # CNN filters\n",
        "\n",
        "# ==============================\n",
        "# 3. LOAD AND PREPROCESS DATA\n",
        "# ==============================\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# ==============================\n",
        "# 4. BUILD THE EXPERT MODEL\n",
        "# ==============================\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding\n",
        "model.add(Embedding(max_features, embedding_dim, input_length=maxlen))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Bidirectional LSTM\n",
        "model.add(Bidirectional(LSTM(lstm_units, return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 1D CNN Layer\n",
        "model.add(Conv1D(filters=cnn_filters, kernel_size=3, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# Dense layers with Dropout\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# ==============================\n",
        "# 5. COMPILE THE MODEL\n",
        "# ==============================\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 6. CALLBACKS\n",
        "# ==============================\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "# ==============================\n",
        "# 7. TRAIN THE MODEL\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=12,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 8. EVALUATE MODEL\n",
        "# ==============================\n",
        "test_loss, test_acc, test_prec, test_rec, test_auc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"\\n===== TEST RESULTS =====\")\n",
        "print(f\"Loss:      {test_loss:.4f}\")\n",
        "print(f\"Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"Precision: {test_prec:.4f}\")\n",
        "print(f\"Recall:    {test_rec:.4f}\")\n",
        "print(f\"AUC:       {test_auc:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 9. PLOT TRAINING HISTORY\n",
        "# ==============================\n",
        "# Accuracy\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Precision\n",
        "plt.figure()\n",
        "plt.plot(history.history['precision'], label='Train Precision')\n",
        "plt.plot(history.history['val_precision'], label='Validation Precision')\n",
        "plt.title('Model Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Recall\n",
        "plt.figure()\n",
        "plt.plot(history.history['recall'], label='Train Recall')\n",
        "plt.plot(history.history['val_recall'], label='Validation Recall')\n",
        "plt.title('Model Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 10. PREDICTION ON SAMPLE REVIEW\n",
        "# ==============================\n",
        "sample_review = x_test[0]\n",
        "sample_review_input = np.expand_dims(sample_review, axis=0)\n",
        "prediction = model.predict(sample_review_input)[0][0]\n",
        "\n",
        "print(f\"\\nPredicted Probability: {prediction:.4f}\")\n",
        "if prediction > 0.5:\n",
        "    print(\"Predicted Sentiment: Positive\")\n",
        "else:\n",
        "    print(\"Predicted Sentiment: Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpI4Uc_cAV64",
        "outputId": "cd952c15-cd07-456f-dd5b-474a1c740f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 676ms/step - accuracy: 0.6408 - auc: 0.7009 - loss: 0.6073 - precision: 0.6406 - recall: 0.6337 - val_accuracy: 0.5926 - val_auc: 0.9456 - val_loss: 0.6288 - val_precision: 0.5481 - val_recall: 0.9972 - learning_rate: 0.0010\n",
            "Epoch 2/12\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 687ms/step - accuracy: 0.9026 - auc: 0.9657 - loss: 0.2378 - precision: 0.9039 - recall: 0.9017 - val_accuracy: 0.8354 - val_auc: 0.9525 - val_loss: 0.5215 - val_precision: 0.7636 - val_recall: 0.9656 - learning_rate: 0.0010\n",
            "Epoch 3/12\n",
            "\u001b[1m 64/157\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 645ms/step - accuracy: 0.9442 - auc: 0.9832 - loss: 0.1697 - precision: 0.9476 - recall: 0.9408 "
          ]
        }
      ]
    }
  ]
}